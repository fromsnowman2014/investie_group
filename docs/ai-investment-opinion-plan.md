물론입니다. 요청하신 문서를 마크다운 형식으로 준비했습니다. 아래 내용을 복사하여 사용하시면 됩니다.

# 구현 계획서: investie\_group AI 투자 의견 모듈

## I. 개요 및 시스템 요약

### 프로젝트 비전

본 프로젝트의 목표는 특정 주식 티커(ticker)에 대해 데이터 기반의 AI 종합 투자 의견을 제공하는 기능을 개발하는 것입니다. 이 기능은 다양한 외부 소스로부터 수집된 거시 경제 지표와 개별 기업 데이터를 AI가 종합적으로 분석하여, 10줄 이내의 간결하고 가독성 높은 요약문 형태로 최종 결과를 제공합니다. 핵심 데이터는 직관적인 시각화 요소와 함께 웹 페이지에 표시되어, 사용자가 원시 금융 데이터를 실행 가능한 인사이트로 전환할 수 있도록 지원하는 것을 비전으로 삼습니다.

### 핵심 기술 전략

시스템 아키텍처는 Python/Flask 기반의 백엔드를 중심으로 설계됩니다. 이 백엔드는 여러 서드파티 API로부터 데이터를 수집하고, 이를 정규화 및 가공한 후, 대규모 언어 모델(LLM)에 전달하여 최종 요약문을 생성하는 오케스트레이터(orchestrator) 역할을 수행합니다. 프론트엔드는 백엔드가 제공하는 단일 통합 API 엔드포인트를 호출하여 사용자 인터페이스를 렌더링합니다. 또한, 시스템의 성능을 최적화하고 API 호출 비용을 관리하기 위해 강력한 캐싱(caching) 계층을 도입하는 것을 핵심 전략으로 삼습니다.

### 시스템 아키텍처 흐름

시스템의 전체 데이터 흐름은 다음과 같이 구성됩니다.

1.  **사용자 (웹 브라우저)**: 프론트엔드(React/Vue.js)와 상호작용합니다.
2.  **프론트엔드**: 사용자가 티커를 입력하면, 백엔드의 단일 API 엔드포인트(`GET /api/opinion/{ticker}`)를 호출합니다.
3.  **백엔드 (Python/Flask)**:
    1.  요청 수신 후, 먼저 \*\*캐시(PostgreSQL/Redis)\*\*에 최신 데이터가 있는지 확인합니다.
    2.  캐시가 없거나 만료된 경우, **데이터 수집 모듈**이 병렬적으로 외부 API를 호출합니다.
          * **Financial Modeling Prep (FMP) API**: PER, EPS, RSI, 뉴스, 섹터 등 마이크로 데이터
          * **FRED (Federal Reserve Economic Data) API**: VIX, 금리, CPI, 실업률 등 매크로 데이터
          * **CNN Production URL**: Fear & Greed Index
    3.  **데이터 처리 엔진**이 수집된 원시 데이터를 정규화하고 분석에 적합한 구조로 가공합니다.
    4.  구조화된 데이터는 \*\*AI 생성 모듈(LLM API)\*\*에 프롬프트 형태로 전달됩니다.
    5.  LLM이 생성한 텍스트 응답은 가공된 데이터와 결합되어 최종 JSON 객체를 구성합니다.
    6.  생성된 최종 JSON 객체는 **캐시**에 저장된 후 프론트엔드로 반환됩니다.

이러한 백엔드 중심의 오케스트레이션 아키텍처는 매우 중요한 설계 결정입니다. 만약 프론트엔드에서 각 데이터 소스의 API를 직접 호출한다면, 클라이언트 측에 API 키가 노출되는 심각한 보안 문제가 발생합니다.[1] 또한, 다수의 API 호출로 인해 사용자 경험이 저하되고, 중앙화된 캐싱 전략을 구현할 수 없어 성능 및 비용 효율성이 떨어집니다. 따라서 백엔드가 모든 외부 통신, 데이터 처리, AI 상호작용을 담당하고 프론트엔드에는 단일화되고 안전한 엔드포인트 하나만을 노출하는 추상화 계층 역할을 수행하도록 설계합니다. 이 구조는 프론트엔드 로직을 단순화하고, 보안을 강화하며, 성능과 비용 효율성을 극대화하는 최적의 방안입니다.

## II. 데이터 수집 계층: 시장 및 기업 정보 소싱

이 섹션에서는 기능 구현에 필요한 모든 외부 데이터 소스의 선정 및 통합 전략을 상세히 기술합니다. API 선정의 주요 기준은 데이터의 가용성, 신뢰성, 비용(안정적인 무료 티어 우선), 그리고 통합의 용이성입니다.

### 거시 경제 지표 (시장 환경)

  * **CNN Fear & Greed Index**:

      * **소스**: CNN의 프로덕션 JSON 엔드포인트에 직접 접근합니다. 연구 자료는 정확한 URL(`https://production.dataviz.cnn.io/index/fearandgreed/graphdata/`)과 Python 구현 가이드를 제공하므로, 웹 스크레이핑보다 안정적이고 구조화된 데이터를 직접 얻을 수 있습니다.[2]
      * **데이터 구조**: API는 시계열 형태의 인덱스 값을 반환하며, 이 중 가장 최신 값만 사용합니다.[2]
      * **중요성**: 이 지수는 시장의 전반적인 투자 심리를 나타내는 고수준의 지표로, AI가 종합 의견을 생성할 때 중요한 정성적 입력값으로 활용됩니다.[3, 4]

  * **VIX (CBOE 변동성 지수)**:

      * **소스**: 미국 연방준비제도 경제 데이터(FRED) API를 사용합니다. 특정 시리즈 ID는 `VIXCLS`입니다.[5] `fredapi` Python 라이브러리 [6] 또는 `pandas-datareader` [7]를 사용하면 Pandas DataFrame으로 데이터를 원활하게 통합할 수 있습니다.
      * **중요성**: '공포 지수'로 불리는 VIX는 시장의 예상 변동성을 직접적으로 측정하는 지표로, 전반적인 위험 환경에 대한 맥락을 제공합니다.[8, 9, 10]

  * **미국 주요 경제 데이터 (금리, CPI, 실업률)**:

      * **소스**: FRED API는 미국 경제 데이터의 가장 신뢰할 수 있는 소스입니다.[11, 12]
      * **시리즈 ID**:
          * **연방 기금 유효 금리 (Federal Funds Effective Rate)**: `FEDFUNDS` [13]
          * **소비자 물가 지수 (Consumer Price Index)**: `CPIAUCSL` [14, 15]
          * **실업률 (Unemployment Rate)**: `UNRATE` [16, 17]
      * **중요성**: 이 세 지표는 통화 정책과 경제 건전성의 핵심 동인으로, 시장 방향성에 대한 필수적인 맥락을 제공합니다. AI는 이 지표들의 추세(예: CPI 상승은 인플레이션 압력 시사)를 해석하도록 지시받게 됩니다.

  * **S\&P 500 / QQQ 차트 데이터**:

      * **소스**: Financial Modeling Prep (FMP) API를 활용합니다. `historical-chart` 엔드포인트는 `^GSPC` (S\&P 500)와 같은 주요 지수의 시계열 데이터를 제공하여 스파크라인(sparkline) 구현을 가능하게 합니다.[18]
      * **중요성**: 주요 지수의 스파크라인은 최근 시장 성과를 즉각적으로 시각화하여 요약 정보를 제공하는, 사용자의 특정 요구사항을 충족시키는 요소입니다.

### 마이크로 경제 지표 (개별 종목 분석)

  * **기본 비율 (PER, EPS)**:

      * **소스**: Financial Modeling Prep (FMP) API를 사용합니다. `key-metrics-ttm/{ticker}` 엔드포인트는 분석에 이상적인 TTM(Trailing Twelve Months) 데이터를 제공합니다.[18] FMP는 광범위한 기본 데이터를 포괄하는 강력한 무료 티어를 제공하므로 주 소스로 선택합니다.[19, 20]
      * **중요성**: PER과 EPS는 가치 평가와 수익성의 기초가 되는 지표입니다. 본 계획은 개별 종목의 PER을 동종 업계 평균과 비교하는 것을 요구하며, 이는 FMP의 `sector_price_earning_ratio` 엔드포인트를 통해 직접 지원됩니다.[21, 22]

  * **기술적 지표 (RSI)**:

      * **소스**: Financial Modeling Prep (FMP) API의 `technical_indicator/daily/{ticker}` 엔드포인트는 RSI 값을 제공합니다.[23] Polygon.io [24, 25]나 Intrinio [26, 27]와 같은 대안이 존재하지만, FMP로 API 의존성을 통합하여 관리를 용이하게 합니다.
      * **중요성**: RSI는 과매수 또는 과매도 상태를 식별하는 데 사용되는 모멘텀 오실레이터로, AI의 단기 기술적 평가에 핵심적인 입력값이 됩니다.

  * **뉴스 요약**:

      * **소스**: FMP의 `stock_news` 엔드포인트는 초기 구현에 적합한 뉴스 헤드라인을 제공합니다.[18] 향후 기능 확장을 고려한다면, DeepSearch와 같은 전문 뉴스 API는 감성 분석 및 AI 브리핑 기능을 제공하여 더 깊이 있는 분석을 가능하게 할 수 있습니다.[28] 초기 버전은 FMP에서 최신 헤드라인을 가져오는 방식으로 구현합니다.
      * **중요성**: 최신 뉴스는 정량적 데이터만으로는 포착할 수 없는 정성적 맥락을 제공합니다. AI는 이를 통해 최근의 주가 촉매제나 리스크 요인을 식별하게 됩니다.

  * **섹터 성과**:

      * **소스**: FMP의 `sector-performance` API는 다양한 시장 섹터의 성과 데이터를 제공합니다.[18, 29]
      * **중요성**: 주식이 속한 섹터의 성과를 파악하는 것은 매우 중요한 맥락을 제공합니다. 하락하는 섹터에서 상승하는 주식은 상대적 강점을, 그 반대는 약점을 의미할 수 있습니다.

  * **추가 요소 (실적 발표일, 배당, 애널리스트 목표가)**:

      * **소스**: 이 모든 데이터 포인트는 FMP의 `analyst-estimates/{ticker}`, `earning_calendar`, `stock_dividend` 등 다양한 엔드포인트에서 제공됩니다.[18, 20]
      * **중요성**: 이들은 투자자와 AI에게 더 완전한 그림을 제공하는 중요한 "추가 요소"입니다.

다수의 API를 통합하는 것은 각 데이터 영역에서 최상의 정보를 얻을 수 있다는 장점이 있지만, 동시에 시스템의 복잡성과 잠재적 실패 지점을 증가시킵니다. 따라서 API 연동 계층을 잠재적으로 실패할 수 있는 중요한 부분으로 간주하고, 각 데이터 소스에 대한 전용 "커넥터(connector)" 모듈을 백엔드에 구현하는 것이 바람직합니다. 이러한 모듈식 설계는 특정 API 제공업체에 문제가 발생하거나 무료 티어의 한계를 초과할 경우, 다른 애플리케이션 로직에 영향을 주지 않고 해당 커넥터만 교체할 수 있는 유연성을 제공합니다. 이는 다양한 API 제공업체들의 장단점을 검토한 결과 도출된 전략적 설계 원칙입니다.[30, 31]

### 데이터 포인트 API 매핑 테이블

다음 표는 개발팀을 위한 단일 정보 소스(source of truth) 역할을 하며, 요구되는 모든 데이터 포인트를 특정 API 엔드포인트에 매핑합니다. 이는 캐싱 전략 수립과 프로젝트 예산 관리에 필수적인 정보인 데이터 소스, 업데이트 주기, 비용 등을 중앙에서 관리할 수 있게 합니다.

| 데이터 포인트 | 분류 | 추천 API | 엔드포인트/시리즈 ID | 업데이트 주기 | 비용/티어 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| Fear & Greed Index | 매크로 | CNN Production URL | `index/fearandgreed/graphdata` | 실시간 | 무료 |
| VIX | 매크로 | FRED | `VIXCLS` | 장 마감 후(EOD) | 무료 |
| 미국 기준 금리 | 매크로 | FRED | `FEDFUNDS` | 월간 | 무료 |
| 미국 CPI | 매크로 | FRED | `CPIAUCSL` | 월간 | 무료 |
| 미국 실업률 | 매크로 | FRED | `UNRATE` | 월간 | 무료 |
| S\&P 500 차트 데이터 | 매크로 | Financial Modeling Prep | `historical-chart/1min/^GSPC` | 지연 | 무료 티어 |
| PER / EPS (TTM) | 마이크로 | Financial Modeling Prep | `key-metrics-ttm/{ticker}` | EOD | 무료 티어 |
| 섹터 평균 PER | 마이크로 | Financial Modeling Prep | `sector_price_earning_ratio` | EOD | 무료 티어 |
| RSI (14일) | 마이크로 | Financial Modeling Prep | `technical_indicator/daily/{ticker}` | EOD | 무료 티어 |
| 뉴스 헤드라인 | 마이크로 | Financial Modeling Prep | `stock_news?tickers={ticker}` | 실시간 | 무료 티어 |
| 섹터 성과 | 마이크로 | Financial Modeling Prep | `sector-performance` | EOD | 무료 티어 |
| 애널리스트 목표가 | 마이크로 | Financial Modeling Prep | `analyst-estimates/{ticker}` | 지연 | 무료 티어 |
| 실적 발표일 | 마이크로 | Financial Modeling Prep | `earning_calendar?symbol={ticker}` | 지연 | 무료 티어 |
| 배당 정보 | 마이크로 | Financial Modeling Prep | `historical-price-full/stock_dividend/{ticker}` | EOD | 무료 티어 |

## III. 백엔드 아키텍처 및 데이터 처리 로직

이 섹션에서는 기능의 핵심 엔진이 될 서버 측 아키텍처를 정의합니다. Python은 데이터 분석과 웹 개발을 위한 광범위한 생태계를 갖추고 있어 백엔드 언어로 권장됩니다.[32, 33, 34]

### 기술 스택

  * **프레임워크**: **Flask** 또는 **FastAPI**. Flask는 본 프로젝트 규모에 적합한 경량화되고 유연한 선택지입니다.
  * **데이터 처리**: **Pandas**. API로부터 가져온 시계열 및 테이블 형식 데이터를 처리하고 변환하는 데 사용됩니다.[35, 36, 37]
  * **데이터베이스/캐시**: **PostgreSQL**과 **SQLAlchemy** ORM. PostgreSQL은 구조화된 데이터 캐싱뿐만 아니라 향후 더 복잡한 쿼리 처리에도 유연하게 대처할 수 있는 강력한 데이터베이스입니다.
  * **HTTP 요청**: `requests` 라이브러리를 사용하여 외부 REST API와 상호작용합니다.[2, 35]
  * **스케줄링**: `APScheduler` 라이브러리를 사용하여 캐시된 데이터를 주기적으로 갱신하는 백그라운드 작업을 실행합니다.

### 데이터 처리 엔진

데이터 처리 엔진은 원시 데이터를 수집하여 프론트엔드와 AI 모델이 요구하는 구조화된 형식으로 변환하는 핵심 로직을 담당합니다.

  * **Fear & Greed Index**: JSON 응답에서 최신 값을 추출한 후, 사전에 정의된 기준에 따라 상태를 매핑합니다. 0-25: "극도의 공포" (빨강), 26-45: "공포" (주황), 46-54: "중립" (노랑), 55-75: "탐욕" (연두), 76-100: "극도의 탐욕" (초록).
  * **VIX**: 최신 값을 가져온 후, S\&P Global의 기준에 따라 상태를 매핑합니다.[8] 15 미만: "낮음" (초록), 15-25: "정상" (노랑), 25 초과: "높음" (빨강).
  * **경제 데이터 (CPI, 실업률)**: 최근 2개월치 데이터를 가져와 전월 대비 변화율을 계산하고 방향성(↑ 또는 ↓)을 결정합니다.
  * **PER**: 해당 기업의 TTM PER과 FMP에서 제공하는 동종 섹터 평균 PER을 가져옵니다.[21] 두 값의 백분율 차이를 계산하고, 사전에 정의된 임계값(예: ±15%)을 기준으로 "저평가", "적정", "고평가"와 같은 정성적 평가를 생성합니다.
  * **EPS**: 최신 분기 EPS와 전년 동기 EPS를 가져와 전년 동기 대비(YoY) 성장률을 계산합니다.
  * **RSI**: 최신 RSI 값을 가져와 상태를 매핑합니다. 30 미만: "과매도", 30-70: "중립", 70 초과: "과매수".[23, 27, 38]
  * **뉴스**: 해당 티커에 대한 최신 뉴스 헤드라인 3-5개를 가져옵니다.

### API 엔드포인트 설계

  * `GET /api/opinion/<string:ticker>`
  * **요청**: 엔드포인트는 주식 티커를 경로 파라미터(path parameter)로 받습니다.
  * **응답**: 처리된 모든 데이터 포인트와 AI가 생성한 의견을 포함하는 단일 JSON 객체를 반환합니다. 이러한 단일 정보 소스 설계는 프론트엔드 개발을 크게 단순화합니다.json
    {
    "macro": {
    "fear\_greed": {"value": 67, "state": "탐욕", "color": "light-green"},
    "vix": {"value": 16.94, "state": "정상", "color": "yellow"},
    "interest\_rate": {"summary": "기준금리 정점 도달 예상"},
    "cpi": {"change": "0.3%", "direction": "↑"},
    "unemployment": {"value": "3.8%", "trend": "전월 대비 상승"}
    },
    "micro": {
    "ticker": "AAPL",
    "per": {"value": 28.5, "comparison": "고평가"},
    "eps\_yoy\_growth": "12.5%",
    "rsi": {"value": 72, "state": "과매수"},
    "sector\_performance\_1w": "+2.4%",
    "analyst\_target": {"price": 210.00, "upside": "15.2%"}
    },
    "additional": {
    "earnings\_date": "2025-10-28",
    "dividend\_yield": "0.54%"
    },
    "ai\_opinion": "AI가 생성한 종합 투자 의견 텍스트..."
    }
    ```
    
    ```

### 캐싱 전략

  * **근거**: API 호출 제한(rate limit) 초과를 방지하고, 비용을 절감하며, 사용자에게 더 빠른 응답 시간을 제공하기 위해 캐싱은 필수적입니다.
  * **구현**: 데이터베이스에 `api_cache`와 같은 테이블을 생성하고, `data_key` (예: `fred_vix`), `data_json`, `last_updated`와 같은 컬럼을 정의합니다.
  * **캐시 유효 기간**:
      * **거시 경제 데이터 (FRED)**: 24시간 (데이터 업데이트 주기가 김)
      * **Fear & Greed Index**: 4시간
      * **주식 펀더멘털 (PER, EPS)**: 12시간 (장 마감 후 갱신)
      * **뉴스, RSI, 가격 데이터**: 15-30분 (상대적으로 잦은 업데이트 필요)
  * **로직**: 백엔드는 외부 API를 호출하기 전에 항상 캐시를 먼저 조회합니다. 유효한(만료되지 않은) 캐시 데이터가 존재하면 해당 데이터를 사용하고, 그렇지 않은 경우에만 외부 API를 호출하여 새로운 데이터를 가져온 후 캐시에 저장하고 타임스탬프를 갱신합니다.

## IV. AI 기반 의견 생성 엔진

이 섹션에서는 가공된 데이터를 종합하여 일관된 서술형 의견으로 변환하는 대규모 언어 모델(LLM)의 통합 방안을 상세히 설명합니다. 이는 프로젝트의 핵심 "AI" 기능으로, 신중한 설계가 요구됩니다.

### LLM 선정

  * **권장 사항**: **OpenAI의 GPT-4 시리즈** 또는 **Anthropic의 Claude 3 제품군**과 같은 최첨단 서드파티 LLM을 API를 통해 활용합니다.
  * **정당성**: 이러한 모델들은 금융 텍스트 생성에 필요한 높은 수준의 추론 능력을 갖추고 있습니다.[39, 40, 41] 금융 특화 LLM(예: FinBERT)을 직접 구축하고 훈련시키는 것은 본 프로젝트의 범위를 훨씬 넘어서는 방대한 작업입니다.[42] API 기반 접근 방식은 이 사용 사례에 있어 가장 빠르고, 확장 가능하며, 비용 효율적인 솔루션입니다.

### 프롬프트 엔지니어링 및 템플릿화

AI의 출력 품질은 전적으로 프롬프트의 설계에 달려 있습니다. 단순히 "이 데이터를 요약해 줘"와 같은 간단한 요청은 일관성 없고 장황한 결과를 낳을 뿐입니다. 보고서 생성 모범 사례에 따르면 [43, 44, 45, 46], LLM을 특정 형식과 톤으로 제한하는 고도로 구조화된 역할 부여(role-playing) 프롬프트를 생성해야 합니다. 이 프롬프트는 백엔드가 처리된 데이터로 채워 넣는 일종의 템플릿 역할을 합니다. 이러한 접근 방식은 결과물의 일관성을 보장하고, 모델이 부정확한 정보를 생성하는 '환각(hallucination)' 현상을 최소화하는 데 결정적입니다.

  * **제안된 프롬프트 구조**:
    ```
    **역할:** 당신은 중립적이고 객관적인 금융 분석 AI입니다. 당신의 임무는 다양한 거시 경제 및 기업별 데이터를 종합하여 간결하고 균형 잡힌 투자 의견을 생성하는 것입니다.

    **제약 조건:**
    1. 최종 결과물은 하나의 텍스트 블록이어야 합니다.
    2. 결과물은 반드시 **10줄 이내**여야 합니다.
    3. 직접적인 매수 또는 매도 추천을 하지 마십시오. "강점을 시사합니다", "잠재적 리스크를 내포합니다", "프리미엄에 거래되고 있습니다"와 같이 중립적이고 객관적인 표현을 사용하십시오.
    4. 가장 먼저 고수준의 요약을 제시한 후, 분석을 뒷받침하기 위해 핵심 데이터 포인트를 통합하십시오.

    **분석 데이터 - 티커: ${ticker} (${company_name})**

    **1. 거시 경제 환경:**
    - 시장 심리 (Fear & Greed Index): ${fgi_state} (${fgi_value}/100).
    - 시장 변동성 (VIX): ${vix_state} (${vix_value}).
    - 미국 금리 전망: ${interest_rate_summary}.
    - 미국 인플레이션 (CPI): 전월 대비 ${cpi_change} ${cpi_direction_arrow}.
    - 미국 실업률: ${unemployment_rate} (${unemployment_trend}).

    **2. 개별 기업 분석:**
    - 가치 평가 (PER): 현재 주가는 PER ${per_value}배로, 동종 섹터 평균(${sector_per_average}배) 대비 **${per_comparison}** 상태로 평가됩니다.
    - 수익성 (EPS 성장): 전년 동기 대비 EPS는 ${eps_yoy_change} 변화했습니다.
    - 기술적 모멘텀 (RSI): 현재 RSI는 ${rsi_value}로, 주가가 **${rsi_state}** 국면에 있음을 시사합니다.
    - 섹터 성과: ${sector_name} 섹터는 최근 1주일간 ${sector_performance_1w}의 수익률을 기록했습니다.
    - 애널리스트 컨센서스: 평균 목표 주가는 $${analyst_target}이며, 이는 현재 주가 대비 ${upside_potential}의 상승 여력을 의미합니다.

    **3. 최신 뉴스 헤드라인:**
    - "${news_headline_1}"
    - "${news_headline_2}"

    **과업:** 위에 제공된 데이터에만 근거하여 투자 의견을 생성하십시오.
    ```

### 입출력 데이터 구조

백엔드는 위 템플릿을 기반으로 단일 문자열을 구성하여 LLM API에 전송합니다. 예상 출력은 간단한 텍스트 문자열이며, 길이를 검증한 후 프론트엔드로 전달될 최종 JSON 응답에 포함됩니다.

### 오류 처리

LLM API 호출이 실패하거나 비정상적인 응답을 반환할 경우, 최종 JSON의 `ai_opinion` 필드에는 "AI 의견을 현재 사용할 수 없습니다."와 같은 기본 메시지를 채워 넣습니다. 나머지 데이터는 정상적으로 프론트엔드에 전달되어, 페이지가 오류 없이 로드될 수 있도록 우아하게(gracefully) 처리합니다.

## V. 프론트엔드 구현 및 사용자 인터페이스

이 섹션에서는 분석된 데이터와 AI 의견을 사용자에게 효과적으로 표시하기 위한 클라이언트 측 개발 계획을 설명합니다.

### 기술 스택

**React** 또는 **Vue.js**와 같은 현대적인 JavaScript 프레임워크를 사용하여 컴포넌트 기반의 반응형 UI를 구축하는 것을 권장합니다.

### 컴포넌트 기반 설계

UI는 논리적이고 재사용 가능한 컴포넌트로 분할하여 설계해야 합니다.

  * `AIOpinionView`: 티커를 입력받아 백엔드 API로부터 데이터를 가져오고, 로딩/오류 상태를 관리하는 메인 컨테이너 컴포넌트.
  * `MacroDashboard`: 모든 거시 경제 지표를 색상으로 구분된 상태 및 값과 함께 표시하는 컴포넌트.
  * `MicroSnapshot`: PER, EPS, RSI 등 개별 종목 관련 데이터를 표시하는 컴포넌트.
  * `AIOpinionBox`: AI가 반환한 텍스트를 서식에 맞게 표시하는 전용 컴포넌트.
  * `SparklineChart`: S\&P 500/QQQ 시각화를 위한 재사용 가능한 차트 컴포넌트.

### 데이터 시각화

  * **라이브러리**: **ApexCharts.js** 또는 **Chart.js**. 이 라이브러리들은 경량화되어 있고 사용이 간편하며, 요구되는 스파크라인 차트를 구현하기에 충분한 기능을 제공합니다.
  * **색상 코딩**: 프론트엔드는 백엔드 JSON 응답에 포함된 `color` 필드를 사용하여 초록/노랑/빨강 상태 표시기에 대한 CSS 클래스를 동적으로 적용합니다.
  * **방향성 화살표**: CPI 및 실업률 추세를 나타내는 유니코드 문자(↑, ↓)는 백엔드의 JSON 응답에서 직접 렌더링합니다.

## VI. 단계별 구현 로드맵

구조화되고 관리 가능한 워크플로우를 보장하기 위해 단계별 개발 계획을 제시합니다.

### 1단계: 백엔드 기반 및 데이터 통합 (스프린트 1-2)

1.  Python/Flask 백엔드 프로젝트 구조를 설정합니다.
2.  캐싱을 위한 데이터베이스 스키마를 구현합니다.
3.  각 API(FMP, FRED, CNN)에 대한 개별 "커넥터" 모듈을 개발합니다.
4.  원시 데이터를 요구되는 구조화된 형식으로 변환하는 데이터 처리 로직을 작성합니다.
5.  각 데이터 포인트의 정확성을 보장하기 위해 철저한 단위 테스트를 수행합니다.

### 2단계: AI 생성 및 API 노출 (스프린트 3)

1.  선택한 LLM 제공업체(예: OpenAI)의 API 키를 발급받습니다.
2.  프롬프트 템플릿 엔진을 구현합니다.
3.  LLM API를 호출하는 서비스를 생성합니다.
4.  데이터 수집, 처리, AI 생성을 통합하는 메인 `/api/opinion/{ticker}` 엔드포인트를 구축합니다.
5.  메인 엔드포인트에 대한 완전한 캐싱 로직을 구현합니다.

### 3단계: 프론트엔드 개발 및 시각화 (스프린트 4-5)

1.  프론트엔드 프로젝트를 설정합니다 (예: `create-react-app`).
2.  설계에 기반하여 정적 UI 컴포넌트를 구축합니다.
3.  백엔드 API를 호출하는 서비스를 구현합니다.
4.  동적 색상 코딩 및 시각화를 포함하여 컴포넌트를 백엔드의 실시간 데이터와 연결합니다.
5.  원활한 사용자 경험을 위해 로딩 및 오류 상태를 구현합니다.

### 4단계: 테스트, 개선 및 배포 (스프린트 6)

1.  다양한 티커를 사용하여 엔드투엔드(end-to-end) 테스트를 수행합니다.
2.  테스트 결과를 바탕으로 AI 프롬프트를 미세 조정하여 생성된 의견의 품질과 일관성을 개선합니다.
3.  프론트엔드 성능과 백엔드 응답 시간을 최적화합니다.
4.  배포를 준비하고(예: Docker를 사용한 컨테이너화), 호스팅 서비스(예: Heroku, AWS)에 배포합니다.

<!-- end list -->

```
```